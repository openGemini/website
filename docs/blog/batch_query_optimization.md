---
blog: true
title: 'openGemini: Batch Query Optimization'
pubDate: '2023-11-24'
author: 'Zhi Chen'
abstract: 'This article introduces what is batch query and the performance problems caused by serial execution of batch query. openGemini makes full use of the powerful concurrent processing capability of Go language to carry out concurrent transformation of serial query, and proposes an adaptive parallel query task scheduler to solve the performance problems of serial query.'
cover: /images/cover/batch_query_optimization.png
recommend: 1
# category: 技术解读 公司动态 案例实践 社区动态 观点洞察
category: 技术解读
tag: openGemini
---

## **Background on batch query optimization**

### **♦ What is batch query?**

Batch query is to package multiple query statements, send them to the database at one time, execute them one by one inside the database, and return the results to the client after summary, which is called batch query.

### **♦** **Batch query scenario**

![img](/images/docs_img/05b7314d8123ef3ef0457d1367d17dd7.png)

In the O&M monitoring scenario, there are a lot of charts on the monitoring panel (the figure above is only part of them), and these charts will query and update data regularly. Some charts may be drawn by hundreds of query results. If all the queries in the charts are sent to the timing database independently, the concurrency will surge, and neither the client nor the database can support it.

![img](/images/docs_img/df9bac1207eba90f60fdb6fb0dfe6141.png)

When batch query is used, semicolon (;) is required between query statements. Divide as follows

```
SELECT disk_usage FROM table; SELECT disk_io FROM table；…
```

### **♦** **Problems caused by batch query**

When a batch query comes, openGemini usually executes each query statement in sequence, and then executes the next one after the execution is complete, so it cannot take advantage of openGemini's concurrency capability. When there are many batch query statements, the query period is often long, which cannot meet the performance requirements. Therefore, optimization requirements are generated.

## **Optimization method**

openGemini's kernel is implemented by Golang, and its GMP model highly supports concurrency, making it ideal for changing from serial to parallel.

-   **Golang GMP Model**

![img](/images/docs_img/9d97b161eff14901e87c3bc561a37b44.png)

KSE is an abbreviation of Kernel Scheduling Entity. It is an object entity that can be scheduled by the operating system kernel scheduler. It is the minimum scheduling unit of the operating system kernel and can be simply understood as kernel-level threads.

**G-M-P stands for:**

G - Goroutine, Go coroutine, it is the smallest unit involved in scheduling and execution

M - Machine, which refers to system-level threads, is generated by system calls

P - Processor, which refers to the logical processor, P associated with the local runnable G queue, can store up to 256 G.

Therefore, to solve the performance problem of serial query, we can make use of the advantages of Golang's GMP model to carry out parallel transformation.

-   **openGemini adaptive parallel query task scheduler**

![img](/images/docs_img/1300498aae8905905eff0c1c5f555555.png)

The openGemini adaptive parallel query task scheduler will create a corresponding number of Goroutines to execute query commands in parallel according to the machine specifications. For example, for a 4U machine, the concurrency is 4 (the highest efficiency). If there are 12 batch query statements and 4 query statements are executed concurrently each time, It only takes 3 rounds to complete the execution, and before the adaptive parallel query task scheduler is not added, 12 query statements have to be executed 12 times, which cannot make full use of the CPU's concurrent capability.

Related source files：open_src/Influx/query/executor.go

Specific methods:

```
func executeParallelQuery()
```

## **Performance reference after optimization**

**Test specifications: (12-node cluster, single-node specifications 32U128G)**

| Query scenario                                                                                                                                            | Concurrent volume | Average time delay(ms) |
| --------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------- | ---------------------- |
| Batch query 50 timelines within an hour, aggregate the average particle size within 1 minute, and the background pressure is 26.5 million timelines       | 100               | 48                     |
| 200                                                                                                                                                       | 53                |                        |
| 300                                                                                                                                                       | 64                |                        |
| 500                                                                                                                                                       | 100               |                        |
| Batch query 100 timelines within 30 minutes and aggregate them by the average value of the 1 minute granularity. Background pressure 26.5 million time 线 | 100               | 59                     |
| 200                                                                                                                                                       | 66                |                        |
| 400                                                                                                                                                       | 108               |                        |

openGemini uses the optimized version v1.1.0. You can enable this function in the configuration file.

// Here is the code block

```
[http]
parallel-query-in-batch-enabled = true
```

## **Summary**

This paper introduces what is batch query and the performance problems caused by serial execution of batch query. openGemini makes full use of the powerful concurrent processing capability of Go language to carry out concurrent transformation of serial query, and proposes an adaptive parallel query task scheduler to solve the performance problems of serial query. I hope this article will help you understand openGemini.

---
